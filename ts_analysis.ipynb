{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mysql.connector\n",
    "import pandas.io.sql as psql\n",
    "import creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a15f72c991496faa224f0ed2fc1548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8cc26036ac40a19f824ffec58684ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78634e05a5e94da7951ad929741ef574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fefbca3a5c0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing numpy's dft\n",
    "\n",
    "def generate_wave(ts, amplitude, frequency, phaseshift):\n",
    "    return amplitude * np.cos(2 * np.pi * frequency * ts + phaseshift)\n",
    "\n",
    "def dft_extrapolate(freqdom, num_datapoints):\n",
    "    n = freqdom.size\n",
    "    amplitudes = np.absolute(freqdom)/n\n",
    "    phaseshifts = np.angle(freqdom)\n",
    "    frequencies = np.fft.fftfreq(n)\n",
    "    ts = np.arange(0, num_datapoints)\n",
    "    # wave = np.sum(generate_wave(np.expand_dims(ts, axis=1), amplitudes, frequencies, phaseshifts), axis=1)\n",
    "    wave = np.zeros(num_datapoints, dtype=np.float)\n",
    "    for i in range(n):\n",
    "        wave = wave + generate_wave(ts, amplitudes[i], frequencies[i], phaseshifts[i])\n",
    "    return wave\n",
    "\n",
    "sr = 1/100 # sampling rate\n",
    "t = np.arange(0,1,sr)\n",
    "t_extended = np.arange(0,1.5,sr)\n",
    "\n",
    "y_0 = generate_wave(t, 2, 10, -1.5*np.pi)\n",
    "# Perform Fourier transform using scipy\n",
    "y_fft = np.fft.fft(y_0)\n",
    "# Plot data\n",
    "n = np.size(t)\n",
    "fr = 1/(2*sr) * np.linspace(0,1,n//2)\n",
    "y_m = 2/n * abs(y_fft[0:np.size(fr)])\n",
    "#y_hat = \n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "ax[0].plot(t, y_0)    # plot time series\n",
    "ax[1].stem(fr, y_m) # plot freq domain\n",
    "ax[2].plot(t_extended, dft_extrapolate(y_fft, len(t_extended)))   # plot inverse fft and extrapolation\n",
    "\n",
    "# https://dsp.stackexchange.com/questions/59921/the-fourier-transform-cannot-measure-two-phases-at-the-same-frequency-why-not\n",
    "y_1 = generate_wave(t, 2, 10, -1.5*np.pi) + generate_wave(t, 1.5, 17, -2.5*np.pi) - 3\n",
    "# Perform Fourier transform using scipy\n",
    "y_fft = np.fft.fft(y_1)\n",
    "# Plot data\n",
    "n = np.size(t)\n",
    "fr = 1/(2*sr) * np.linspace(0,1,n//2)\n",
    "y_m = 2/n * abs(y_fft[0:np.size(fr)])\n",
    "#y_hat = \n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "ax[0].plot(t, y_1)    # plot time series\n",
    "ax[1].stem(fr, y_m) # plot freq domain\n",
    "ax[2].plot(t_extended, dft_extrapolate(y_fft, len(t_extended)))   # plot inverse fft and extrapolation\n",
    "\n",
    "# fft not good at modeling series with trend components in addition to oscillations\n",
    "y_2 = generate_wave(t, 2, 10, -1.5*np.pi) + generate_wave(t, 1.5, 17, -2.5*np.pi) + t*20\n",
    "# Perform Fourier transform using scipy\n",
    "y_fft = np.fft.fft(y_2)\n",
    "# Plot data\n",
    "n = np.size(t)\n",
    "fr = 1/(2*sr) * np.linspace(0,1,n//2)\n",
    "y_m = 2/n * abs(y_fft[0:np.size(fr)])\n",
    "#y_hat = \n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "ax[0].plot(t, y_2)    # plot time series\n",
    "ax[1].stem(fr, y_m) # plot freq domain\n",
    "ax[2].plot(t_extended, dft_extrapolate(y_fft, len(t_extended)))   # plot inverse fft and extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(statement):\n",
    "  \"\"\"\n",
    "  establishes a connection and makes a query\n",
    "  :param statement: sql\n",
    "  :return: pandas data frame\n",
    "  \"\"\"\n",
    "  conn = mysql.connector.connect(user=creds.USERNAME, password=creds.PASSWORD,\n",
    "                                 host='127.0.0.1', database=creds.SCHEMA)\n",
    "  df = psql.read_sql_query(statement, conn)\n",
    "  conn.close()\n",
    "  return df\n",
    "\n",
    "# query database\n",
    "df = query(\"SELECT size, time FROM hourly_post_sizes WHERE siteId=\" + str(156) + \" ORDER BY time ASC\")\n",
    "# convert to time series format\n",
    "df['time'] = pd.to_datetime(df[\"time\"])\n",
    "df.set_index('time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2008-07-31 21:00:00</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-07-31 22:00:00</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-07-31 23:00:00</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-08-01 00:00:00</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-08-01 04:00:00</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 16:00:00</td>\n",
       "      <td>599877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 17:00:00</td>\n",
       "      <td>502281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 18:00:00</td>\n",
       "      <td>620185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 19:00:00</td>\n",
       "      <td>478912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 20:00:00</td>\n",
       "      <td>417681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94955 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       size\n",
       "time                       \n",
       "2008-07-31 21:00:00     507\n",
       "2008-07-31 22:00:00    1096\n",
       "2008-07-31 23:00:00    1351\n",
       "2008-08-01 00:00:00     481\n",
       "2008-08-01 04:00:00    1018\n",
       "...                     ...\n",
       "2019-06-01 16:00:00  599877\n",
       "2019-06-01 17:00:00  502281\n",
       "2019-06-01 18:00:00  620185\n",
       "2019-06-01 19:00:00  478912\n",
       "2019-06-01 20:00:00  417681\n",
       "\n",
       "[94955 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some of the hourly increments are missing because no questions were posted during those hours\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2010-10-01 21:00:00</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-10-01 21:00:00</td>\n",
       "      <td>216012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-12-01 21:00:00</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-12-01 21:00:00</td>\n",
       "      <td>349036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-06-01 21:00:00</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-06-01 21:00:00</td>\n",
       "      <td>419210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-09-01 21:00:00</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-09-01 21:00:00</td>\n",
       "      <td>454460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-11-01 21:00:00</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011-11-01 21:00:00</td>\n",
       "      <td>434095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-05-01 21:00:00</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-05-01 21:00:00</td>\n",
       "      <td>584662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-08-01 21:00:00</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012-08-01 21:00:00</td>\n",
       "      <td>538877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-06-01 21:00:00</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-06-01 21:00:00</td>\n",
       "      <td>392474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-03-01 21:00:00</td>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-03-01 21:00:00</td>\n",
       "      <td>602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-11-01 21:00:00</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-11-01 21:00:00</td>\n",
       "      <td>383004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-12-01 21:00:00</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-12-01 21:00:00</td>\n",
       "      <td>863180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-04-01 21:00:00</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-04-01 21:00:00</td>\n",
       "      <td>711989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-08-01 21:00:00</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-08-01 21:00:00</td>\n",
       "      <td>398841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-12-01 21:00:00</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-12-01 21:00:00</td>\n",
       "      <td>897602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-08-01 21:00:00</td>\n",
       "      <td>9098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-08-01 21:00:00</td>\n",
       "      <td>849821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-09-01 21:00:00</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-09-01 21:00:00</td>\n",
       "      <td>731961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-12-01 21:00:00</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-12-01 21:00:00</td>\n",
       "      <td>849706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-02-01 21:00:00</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-02-01 21:00:00</td>\n",
       "      <td>920817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-03-01 21:00:00</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-03-01 21:00:00</td>\n",
       "      <td>1011477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-02-01 21:00:00</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-02-01 21:00:00</td>\n",
       "      <td>801869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-03-01 21:00:00</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-03-01 21:00:00</td>\n",
       "      <td>803750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-06-01 21:00:00</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-06-01 21:00:00</td>\n",
       "      <td>502079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-08-01 21:00:00</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-08-01 21:00:00</td>\n",
       "      <td>729284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        size\n",
       "time                        \n",
       "2010-10-01 21:00:00      154\n",
       "2010-10-01 21:00:00   216012\n",
       "2010-12-01 21:00:00     2048\n",
       "2010-12-01 21:00:00   349036\n",
       "2011-06-01 21:00:00      600\n",
       "2011-06-01 21:00:00   419210\n",
       "2011-09-01 21:00:00     1135\n",
       "2011-09-01 21:00:00   454460\n",
       "2011-11-01 21:00:00     1109\n",
       "2011-11-01 21:00:00   434095\n",
       "2012-05-01 21:00:00     1095\n",
       "2012-05-01 21:00:00   584662\n",
       "2012-08-01 21:00:00      300\n",
       "2012-08-01 21:00:00   538877\n",
       "2013-06-01 21:00:00     1808\n",
       "2013-06-01 21:00:00   392474\n",
       "2014-03-01 21:00:00     1365\n",
       "2014-03-01 21:00:00   602611\n",
       "2014-11-01 21:00:00      182\n",
       "2014-11-01 21:00:00   383004\n",
       "2014-12-01 21:00:00      355\n",
       "2014-12-01 21:00:00   863180\n",
       "2015-04-01 21:00:00      539\n",
       "2015-04-01 21:00:00   711989\n",
       "2015-08-01 21:00:00      342\n",
       "2015-08-01 21:00:00   398841\n",
       "2015-12-01 21:00:00      497\n",
       "2015-12-01 21:00:00   897602\n",
       "2016-08-01 21:00:00     9098\n",
       "2016-08-01 21:00:00   849821\n",
       "2016-09-01 21:00:00     1456\n",
       "2016-09-01 21:00:00   731961\n",
       "2016-12-01 21:00:00     1379\n",
       "2016-12-01 21:00:00   849706\n",
       "2017-02-01 21:00:00     2234\n",
       "2017-02-01 21:00:00   920817\n",
       "2017-03-01 21:00:00      522\n",
       "2017-03-01 21:00:00  1011477\n",
       "2018-02-01 21:00:00     1925\n",
       "2018-02-01 21:00:00   801869\n",
       "2018-03-01 21:00:00     1114\n",
       "2018-03-01 21:00:00   803750\n",
       "2018-06-01 21:00:00      167\n",
       "2018-06-01 21:00:00   502079\n",
       "2018-08-01 21:00:00     1435\n",
       "2018-08-01 21:00:00   729284"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it also appears that there are some duplicates, probably small errors in spark map reductions\n",
    "df[df.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix duplicates by removing the first occurances\n",
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2008-07-31 21:00:00</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-07-31 22:00:00</td>\n",
       "      <td>1096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-07-31 23:00:00</td>\n",
       "      <td>1351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-08-01 00:00:00</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-08-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 16:00:00</td>\n",
       "      <td>599877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 17:00:00</td>\n",
       "      <td>502281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 18:00:00</td>\n",
       "      <td>620185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 19:00:00</td>\n",
       "      <td>478912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 20:00:00</td>\n",
       "      <td>417681.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94968 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         size\n",
       "time                         \n",
       "2008-07-31 21:00:00     507.0\n",
       "2008-07-31 22:00:00    1096.0\n",
       "2008-07-31 23:00:00    1351.0\n",
       "2008-08-01 00:00:00     481.0\n",
       "2008-08-01 01:00:00       0.0\n",
       "...                       ...\n",
       "2019-06-01 16:00:00  599877.0\n",
       "2019-06-01 17:00:00  502281.0\n",
       "2019-06-01 18:00:00  620185.0\n",
       "2019-06-01 19:00:00  478912.0\n",
       "2019-06-01 20:00:00  417681.0\n",
       "\n",
       "[94968 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in missing hour increments for when nothing is posted by users\n",
    "df = df.asfreq('H').fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5e5ef6ff894eff9a0c8d1e25a67d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='time'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>size_cma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2008-07-31 21:00:00</td>\n",
       "      <td>507.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-07-31 22:00:00</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-07-31 23:00:00</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-08-01 00:00:00</td>\n",
       "      <td>481.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-08-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 16:00:00</td>\n",
       "      <td>599877.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 17:00:00</td>\n",
       "      <td>502281.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 18:00:00</td>\n",
       "      <td>620185.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 19:00:00</td>\n",
       "      <td>478912.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-06-01 20:00:00</td>\n",
       "      <td>417681.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         size  size_cma\n",
       "time                                   \n",
       "2008-07-31 21:00:00     507.0       NaN\n",
       "2008-07-31 22:00:00    1096.0       NaN\n",
       "2008-07-31 23:00:00    1351.0       NaN\n",
       "2008-08-01 00:00:00     481.0       NaN\n",
       "2008-08-01 01:00:00       0.0       NaN\n",
       "...                       ...       ...\n",
       "2019-06-01 16:00:00  599877.0       NaN\n",
       "2019-06-01 17:00:00  502281.0       NaN\n",
       "2019-06-01 18:00:00  620185.0       NaN\n",
       "2019-06-01 19:00:00  478912.0       NaN\n",
       "2019-06-01 20:00:00  417681.0       NaN\n",
       "\n",
       "[94968 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integrate out oscillations with center moving averages\n",
    "df = df.join(df.rolling(int(24*365.25), center=True).mean(), rsuffix=\"_cma\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ed75aa6a22409981857bb5599e3ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='time'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83691c2082c64545b51c3b0b402ecd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141a9b87a07a40e1a29d3beb0c5888d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='time'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df['size_cma'].notnull()].copy()\n",
    "filtered_df['size_detrended'] = filtered_df['size'].values/filtered_df['size_cma'].values - 1\n",
    "filtered_df[['size_detrended']].plot()\n",
    "filtered_df['size_detrended_scaled'] = (filtered_df['size_detrended'] + 1) * filtered_df['size_cma'].mean()\n",
    "df.join(filtered_df[['size_detrended_scaled']])[['size', 'size_detrended_scaled']].plot(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c293558654c4fcb90c6cbb5e8477ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4daf5f470348feab24bb292157b2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_horizon_start = np.datetime64(\"2011-01-01T00:00:00\")\n",
    "forecast_horizon_start = np.datetime64(\"2017-01-01T00:00:00\")\n",
    "df['t'] = df.index - fit_horizon_start\n",
    "\n",
    "def plot_datetime_df_with_highlighted_horizon(dataframe):\n",
    "    ax = dataframe.plot()\n",
    "    ax.axvspan(fit_horizon_start, forecast_horizon_start, facecolor='green', edgecolor='none', alpha=.4)\n",
    "    ax.axvspan(forecast_horizon_start, dataframe.index[-1], facecolor='orange', edgecolor='none', alpha=.4)\n",
    "    ax.set_title('Model fitting horizon is green; Forecast horizon is yellow.', loc='right', fontdict={'fontsize':6})\n",
    "\n",
    "plot_datetime_df_with_highlighted_horizon(filtered_df[['size_detrended']])\n",
    "plot_datetime_df_with_highlighted_horizon(df[['size', 'size_cma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_horizon = filtered_df[fit_horizon_start:forecast_horizon_start - np.timedelta64(1,\"h\")].copy()\n",
    "signal_fft = np.fft.fft(fitting_horizon['size_detrended'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 60**-2 # once per hour in Hz\n",
    "n = len(fitting_horizon)\n",
    "non_constant_signal_fft = signal_fft[1:] # first term has frequency of zero which is just a constant term\n",
    "amplitudes = np.absolute(non_constant_signal_fft)/n\n",
    "frequencies_hz = (np.arange(0, n, 1) * sample_rate / n)[1:]\n",
    "\n",
    "periods_hours = (1/frequencies_hz)/((60**2))\n",
    "periods_days = (1/frequencies_hz)/((60**2)*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34986b1f24484ae4923328241f9db1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1a8e50ef0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Period (Hours)\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "secax = ax.secondary_xaxis('top', functions=(lambda x:x/24, lambda x:x*24))\n",
    "secax.set_xlabel('Period (Days)')\n",
    "ax.plot(periods_hours, amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_indices = df.index >= forecast_horizon_start\n",
    "cmas = df['size_cma'].values.copy()\n",
    "cmas[forecast_indices] = fitting_horizon['size_cma'].values[-1]\n",
    "df['cma_for_extrapolation'] = cmas\n",
    "\n",
    "# taking an extremely long time because time complexity is O(n*m)\n",
    "# , where n is the length of DFT series (length of fitting horizon)\n",
    "# , and m is the length of extrapolation\n",
    "\n",
    "# also we need to see a plot not just an error number to troubleshoot any issues\n",
    "\n",
    "# df['forecasts'] = np.nan\n",
    "# forecasts = df['forecasts'].values.copy()\n",
    "# num_extrapolations = len(df[fit_horizon_start:])\n",
    "# extrapolation_indices = df.index >= fit_horizon_start\n",
    "# forecasts[extrapolation_indices] = cmas[extrapolation_indices] *  (dft_extrapolate(signal_fft, num_extrapolations) + 1)\n",
    "# df['forecasts'] = forecasts\n",
    "# df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "# forecast_horizon = df[forecast_horizon_start:]\n",
    "# print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "# print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 182641.82213338636\n",
      "Relative Mean Error: 0.26504276383934694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82face934bd24ca796d0cff032d82221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# numpy implementation way too slow\n",
    "# implement parallel extrapolation with gpu\n",
    "\n",
    "# appears to always underforecast mondays and overforecast saturdays\n",
    "import cupy as cp\n",
    "\n",
    "def dft_extrapolate_cuda(freqdom, num_datapoints):\n",
    "    num_batches = 20\n",
    "    n = freqdom.size\n",
    "    gen_wave = lambda t, A, f, phi: A * cp.cos(2 * cp.pi * f * t + phi)\n",
    "    freqdom = cp.array(freqdom)\n",
    "    amplitudes = cp.absolute(freqdom)/n\n",
    "    phaseshifts = cp.angle(freqdom)\n",
    "    frequencies = cp.fft.fftfreq(n)\n",
    "    batch_size = num_datapoints // num_batches\n",
    "    results = cp.empty(num_datapoints)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in range(num_batches):\n",
    "        start = batch_size * i\n",
    "        end = num_datapoints if end > num_datapoints else batch_size * (i + 1)\n",
    "        t_slice = cp.arange(start, end)\n",
    "        results[start:end] = cp.sum(gen_wave(cp.expand_dims(t_slice, axis=1), amplitudes, frequencies, phaseshifts), axis=1)\n",
    "    return cp.asnumpy(results)\n",
    "\n",
    "def plot_forecasts(dataframe, fit_start=fit_horizon_start, forecast_start=forecast_horizon_start):\n",
    "    ax = dataframe[['size', 'cma_for_extrapolation', 'forecasts']].plot(alpha=.6)\n",
    "    ax.axvspan(fit_start, forecast_start, facecolor='green', edgecolor='none', alpha=.4)\n",
    "    ax.axvspan(forecast_start, dataframe.index[-1], facecolor='orange', edgecolor='none', alpha=.4)\n",
    "    ax.set_title('Model fitting horizon is green; Forecast horizon is yellow.', loc='right', fontdict={'fontsize':6})\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[fit_horizon_start:])\n",
    "extrapolation_indices = df.index >= fit_horizon_start\n",
    "forecasts[extrapolation_indices] = cmas[extrapolation_indices] *  (dft_extrapolate_cuda(signal_fft, num_extrapolations) + 1)\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "\n",
    "plot_forecasts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 287686.8361918207\n",
      "Relative Mean Error: 0.41748003438550607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b70086ec8fe4536b84b19b1c274756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we verify that our CMA staionarization was not making things worse\n",
    "# because without it, the error is twice as bad - it's just repeating the original signal\n",
    "# we dont want to repeat the original signal. we want to find periodical trends with fourier terms\n",
    "# also the monday underforecasting is still there\n",
    "\n",
    "# CONCLUSION 1\n",
    "# staionarity is important for fourier extrapolation of time series\n",
    "nonstationary_signal_fft = np.fft.fft(fitting_horizon['size'])\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[fit_horizon_start:])\n",
    "extrapolation_indices = df.index >= fit_horizon_start\n",
    "forecasts[extrapolation_indices] = dft_extrapolate_cuda(nonstationary_signal_fft, num_extrapolations)\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "\n",
    "plot_forecasts(df, fit_horizon_start, forecast_horizon_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 102504.52184563583\n",
      "Relative Mean Error: 0.1487506062886119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372f4a9fd22144a09c07c8eab35c90ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cheat and shift the forecast left by a day and see if it fixes the errors\n",
    "# indeed we find that our forecasting series have the weekdays somehow misaligned\n",
    "# how can we fix this without cheating?\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[fit_horizon_start:])\n",
    "num_forecasts = len(df[forecast_horizon_start:])\n",
    "extrapolation_indices = df.index >= fit_horizon_start\n",
    "fits = np.append(cmas[extrapolation_indices], [cmas[-1]]*24) *  (dft_extrapolate_cuda(signal_fft, num_extrapolations + 24) + 1)\n",
    "fits[num_extrapolations - num_forecasts:num_extrapolations] = fits[num_extrapolations - num_forecasts + 24:num_extrapolations + 24]\n",
    "forecasts[extrapolation_indices] = fits[:num_extrapolations]\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "plot_forecasts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 241691.4717650444\n",
      "Relative Mean Error: 0.3507333365641951\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16cd106f96a4900aac81efaaea4abc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter out high frequency terms (\"noise\"), low frequency terms (trend), and low amplitude terms and see if it fixes the issue without cheating\n",
    "# actually made predictions worse\n",
    "def dft_extrapolate_filtered_cpu(freqdom, num_datapoints, index_filter_conditions):\n",
    "    n = freqdom.size\n",
    "    amplitudes = np.absolute(freqdom)/n\n",
    "    phaseshifts = np.angle(freqdom)\n",
    "    frequencies = np.fft.fftfreq(n)\n",
    "    ts = np.arange(0, num_datapoints)\n",
    "    # wave = np.sum(generate_wave(np.expand_dims(ts, axis=1), amplitudes, frequencies, phaseshifts), axis=1)\n",
    "    indices = np.arange(n)\n",
    "    unfiltered_indices = indices[~index_filter_conditions]\n",
    "    return np.sum(generate_wave(np.expand_dims(ts, axis=1), amplitudes[unfiltered_indices], frequencies[unfiltered_indices], phaseshifts[unfiltered_indices]), axis=1)\n",
    "\n",
    "filtered_indices = np.insert((periods_days < 5) + (periods_days > 365.25) + (amplitudes < 0.005),0,[True])\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[fit_horizon_start:])\n",
    "extrapolation_indices = df.index >= fit_horizon_start\n",
    "forecasts[extrapolation_indices] = cmas[extrapolation_indices] *  (dft_extrapolate_filtered_cpu(signal_fft, num_extrapolations, filtered_indices) + 1)\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "plot_forecasts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 171694.21328697065\n",
      "Relative Mean Error: 0.24915601636719883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0447178f804a2ab032b9ba959f2491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter out only low frequency terms (trend) and low amp terms and see if it fixes the issue without cheating\n",
    "# helps a little, will keep this change for future iterations\n",
    "filtered_indices = np.insert((periods_days > 365.25) + (amplitudes < 0.005),0,[True])\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[fit_horizon_start:])\n",
    "extrapolation_indices = df.index >= fit_horizon_start\n",
    "forecasts[extrapolation_indices] = cmas[extrapolation_indices] *  (dft_extrapolate_filtered_cpu(signal_fft, num_extrapolations, filtered_indices) + 1)\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "plot_forecasts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 253875.59491120456\n",
      "Relative Mean Error: 0.3684144658690639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10dc433911d461abeba55e619f788bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# maybe having a more recent fitting horizon can improve our model rather than one that starts from 2011?\n",
    "# nope - made things worse\n",
    "# also the weekdays are still misaligned - now it's overforecasting weekends and underforecasting Tue and Wed\n",
    "# could it be caused by the starting time of the signal?\n",
    "# for the 2015 - 2017 fitting horizon, the signal starts on a Thursday - Friday - Saturday - Sunday\n",
    "# notice 2017 starts on Sunday - Mon - Tue - Wed\n",
    "# could this misalignment between weekday be causing the systematic over and underforecasting of those weekdays????\n",
    "shorter_fit_horizon_start = np.datetime64(\"2015-01-01T00:00:00\")\n",
    "shorter_fitting_horizon = filtered_df[shorter_fit_horizon_start:forecast_horizon_start - np.timedelta64(1,\"h\")].copy()\n",
    "shorter_signal_fft = np.fft.fft(shorter_fitting_horizon['size_detrended'])\n",
    "\n",
    "n = len(shorter_fitting_horizon)\n",
    "non_constant_signal_fft = shorter_signal_fft[1:] # first term has frequency of zero which is just a constant term\n",
    "amplitudes = np.absolute(non_constant_signal_fft)/n\n",
    "frequencies_hz = (np.arange(0, n, 1) * sample_rate / n)[1:]\n",
    "periods_hours = (1/frequencies_hz)/((60**2))\n",
    "periods_days = (1/frequencies_hz)/((60**2)*24)\n",
    "filtered_indices = np.insert((periods_days > 365.25) + (amplitudes < 0.005),0,[True])\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[shorter_fit_horizon_start:])\n",
    "num_forecasts = len(df[forecast_horizon_start:])\n",
    "extrapolation_indices = df.index >= shorter_fit_horizon_start\n",
    "fits = cmas[extrapolation_indices] *  (dft_extrapolate_filtered_cpu(shorter_signal_fft, num_extrapolations, filtered_indices) + 1)\n",
    "forecasts[extrapolation_indices] = fits\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "\n",
    "plot_forecasts(df, shorter_fit_horizon_start, forecast_horizon_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: 78285.85510525809\n",
      "Relative Mean Error: 0.11360541175213879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8ebe944fb84364bd6439b18f03ca97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's try starting the fitting horizon on 2012 which starts on a sunday, like 2017\n",
    "# led to much lower error!!!!! \n",
    "# only around 10% off relatively, which is really good considering we are predicting 8760 steps ahead\n",
    "# no more underforecasting on mondays or overfasting on saturdays!!!\n",
    "\n",
    "# CONCLUSION 2\n",
    "# sample and forecast need to have the start of their time respective periods aligned for fourer model\n",
    "# otherwise the waves dont line up as they should for extrapolation\n",
    "sunday_fit_horizon_start = np.datetime64(\"2012-01-01T00:00:00\")\n",
    "sunday_fitting_horizon = filtered_df[sunday_fit_horizon_start:forecast_horizon_start - np.timedelta64(1,\"h\")].copy()\n",
    "sunday_signal_fft = np.fft.fft(sunday_fitting_horizon['size_detrended'])\n",
    "\n",
    "n = len(sunday_fitting_horizon)\n",
    "non_constant_signal_fft = sunday_signal_fft[1:] # first term has frequency of zero which is just a constant term\n",
    "amplitudes = np.absolute(non_constant_signal_fft)/n\n",
    "frequencies_hz = (np.arange(0, n, 1) * sample_rate / n)[1:]\n",
    "periods_hours = (1/frequencies_hz)/((60**2))\n",
    "periods_days = (1/frequencies_hz)/((60**2)*24)\n",
    "filtered_indices = np.insert((periods_days > 365.25) + (amplitudes < 0.005),0,[True])\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[sunday_fit_horizon_start:])\n",
    "num_forecasts = len(df[forecast_horizon_start:])\n",
    "extrapolation_indices = df.index >= sunday_fit_horizon_start\n",
    "fits = cmas[extrapolation_indices] *  (dft_extrapolate_filtered_cpu(sunday_signal_fft, num_extrapolations, filtered_indices) + 1)\n",
    "forecasts[extrapolation_indices] = fits\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "\n",
    "plot_forecasts(df, sunday_fit_horizon_start, forecast_horizon_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try starting our horizons on fridays\n",
    "friday_fit_horizon_start = np.datetime64(\"2010-01-01T00:00:00\")\n",
    "friday_fitting_horizon = filtered_df[friday_fit_horizon_start:forecast_horizon_start - np.timedelta64(1,\"h\")].copy()\n",
    "friday_signal_fft = np.fft.fft(friday_fitting_horizon['size_detrended'])\n",
    "\n",
    "friday_forecast_horizon_start = \n",
    "\n",
    "n = len(friday_fitting_horizon)\n",
    "non_constant_signal_fft = sunday_signal_fft[1:] # first term has frequency of zero which is just a constant term\n",
    "amplitudes = np.absolute(non_constant_signal_fft)/n\n",
    "frequencies_hz = (np.arange(0, n, 1) * sample_rate / n)[1:]\n",
    "periods_hours = (1/frequencies_hz)/((60**2))\n",
    "periods_days = (1/frequencies_hz)/((60**2)*24)\n",
    "filtered_indices = np.insert((periods_days > 365.25) + (amplitudes < 0.005),0,[True])\n",
    "\n",
    "df['forecasts'] = np.nan\n",
    "forecasts = df['forecasts'].values.copy()\n",
    "num_extrapolations = len(df[friday_fit_horizon_start:])\n",
    "num_forecasts = len(df[forecast_horizon_start:])\n",
    "extrapolation_indices = df.index >= friday_fit_horizon_start\n",
    "fits = cmas[extrapolation_indices] *  (dft_extrapolate_filtered_cpu(sunday_signal_fft, num_extrapolations, filtered_indices) + 1)\n",
    "forecasts[extrapolation_indices] = fits\n",
    "df['forecasts'] = forecasts\n",
    "df['errors'] = (df['forecasts'] - df['size']).abs()\n",
    "\n",
    "forecast_horizon = df[forecast_horizon_start:]\n",
    "print(f\"Mean Error: {forecast_horizon['errors'].mean()}\")\n",
    "print(f\"Relative Mean Error: {forecast_horizon['errors'].mean()/forecast_horizon['size'].mean()}\")\n",
    "\n",
    "plot_forecasts(df, friday_fit_horizon_start, forecast_horizon_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMMARY of FFT for Time Series\n",
    "# Pros: 1. widely researched and implemented, with existing libraries 2. Very good at modeling periodic trends in time series\n",
    "# Cons: 1. Need a way to staitionarize the series to take out non-periodtic trends 2. Very sensitive to alignment of fitting and forecasting periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUTURE WORK\n",
    "# 1. compare DFT method to \"orthodox\" seasonal forecasting models such as SARIMA\n",
    "# 2. analyze differences in traffic patterns between different stack exchange sites (for example, academia stack exchange and stackoverflow)\n",
    "# 3. analyze effects of COVID19 on traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA\n",
    "\n",
    "# we will use a grid search procedure to find the empiricially best parameters\n",
    "\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# def sarima_forecast_onestep(history, config, cma_for_forecast):\n",
    "# \torder, sorder, trend = config\n",
    "# \t# define model\n",
    "# \tmodel = SARIMAX(history, order=order, seasonal_order=sorder, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "# \t# fit model\n",
    "# \tmodel_fit = model.fit(disp=False)\n",
    "# \t# make one step forecast\n",
    "# \tyhat = (model_fit.forecast() + 1) * cma_for_forecast\n",
    "# \treturn yhat\n",
    "\n",
    "# def sarima_forecast_multistep(history, config, target_date, cmas_for_forecast):\n",
    "# \torder, sorder, trend = config\n",
    "# \t# define model\n",
    "# \tmodel = SARIMAX(history, order=order, seasonal_order=sorder, trend=trend, enforce_stationarity=False, enforce_invertibility=False)\n",
    "# \t# fit model\n",
    "# \tmodel_fit = model.fit(disp=False)\n",
    "# \t# make one step forecast\n",
    "# \tyhats = (model_fit.forecast(steps=target_date) + 1) * cmas_for_forecast\n",
    "# \treturn yhats\n",
    "\n",
    "# train_series = sunday_fitting_horizon['size_detrended'].values\n",
    "# test_series = forecast_horizon['size'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
