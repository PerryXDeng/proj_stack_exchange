{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: 2019-01-01\n",
      "End Date: 2019-04-30\n",
      "reading in data from stack overflow\n",
      "reading in data from software engineering\n",
      "Data size: 9296\n",
      "Fitting model...\n",
      "Saving model...\n",
      "Start Date: 2019-01-01\n",
      "End Date: 2019-01-31\n",
      "reading in data from stack overflow\n",
      "reading in data from software engineering\n",
      "Data size: 6197\n",
      "accuracy of model: 0.8638050669678877\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                    stackoverflow.com       0.99      0.84      0.91      5001\n",
      "softwareengineering.stackexchange.com       0.59      0.98      0.74      1196\n",
      "\n",
      "                          avg / total       0.92      0.86      0.87      6197\n",
      "\n",
      "[[4181  820]\n",
      " [  24 1172]]\n",
      "Start Date: 2019-01-01\n",
      "End Date: 2019-04-30\n",
      "reading in data from stack overflow\n",
      "reading in data from software engineering\n",
      "Data size: 9296\n",
      "Fitting model...\n",
      "Saving model...\n",
      "Start Date: 2019-01-01\n",
      "End Date: 2019-01-31\n",
      "reading in data from stack overflow\n",
      "reading in data from software engineering\n",
      "Data size: 6197\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "                    stackoverflow.com       0.97      0.94      0.95      5001\n",
      "softwareengineering.stackexchange.com       0.77      0.87      0.82      1196\n",
      "\n",
      "                          avg / total       0.93      0.92      0.93      6197\n",
      "\n",
      "[[4692  309]\n",
      " [ 159 1037]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext, functions\n",
    "from creds import USERNAME as UNAME\n",
    "from creds import PASSWORD as PASS\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "SCHEMA = \"main_v2\"\n",
    "URL = \"jdbc:mysql://localhost:3306/\" + SCHEMA\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Database access example\") \\\n",
    "    .config('spark.driver.extraClassPath', './mysql-connector-java-8.0.16.jar') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sql_context = SQLContext(sc)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "\n",
    "def execute_query(sql_query):\n",
    "  \"\"\"\n",
    "  Executes an arbitrary sql statement and returns the dataframe that is loaded into memory\n",
    "  \"\"\"\n",
    "  # TODO: make generic for each type of clause in a query?\n",
    "  return sql_context.read.format(\"jdbc\").options(\n",
    "      url=URL,\n",
    "      user=UNAME,\n",
    "      password=PASS,\n",
    "      query=sql_query).load()\n",
    "\n",
    "def get_posts(siteId, start, end):\n",
    "    query = \"SELECT body FROM post WHERE dateCreated BETWEEN \\\"{0}\\\" AND \\\"{1}\\\" AND siteId = {2} LIMIT 5000\"\n",
    "    sql_query = query.format(start, end, siteId)\n",
    "    #print(sql_query)\n",
    "    return execute_query(sql_query)\n",
    "\n",
    "def format_post_data(start_date, end_date):\n",
    "    print(\"Start Date: \" + start_date.strftime(\"%Y-%m-%d\"))\n",
    "    print(\"End Date: \" + end_date.strftime(\"%Y-%m-%d\"))\n",
    "    print(\"reading in data from stack overflow\")\n",
    "     # posts from 3d printing\n",
    "    print_posts = [BeautifulSoup(p, \"lxml\").get_text() for p in map(lambda p: p.body, get_posts(156, start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).collect())]\n",
    "    # posts from academia\n",
    "    print(\"reading in data from software engineering\")\n",
    "    academia_posts = [BeautifulSoup(p, \"lxml\").get_text() for p in map(lambda p: p.body, get_posts(127, start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")).collect())]\n",
    "    train_data = print_posts + academia_posts\n",
    "    # shuffle data so no ordering bias\n",
    "    shuffle(train_data)\n",
    "    print(\"Data size: \" + str(len(train_data)))\n",
    "    # labels for the data\n",
    "    targets = np.array([1 if x in print_posts else 2 for x in train_data])\n",
    "    return (train_data, targets)\n",
    "\n",
    "def train_bayes():\n",
    "    # pipeline for ML architecture\n",
    "    text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB()),])\n",
    "    # the date range to train with\n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 4, 30)\n",
    "    train_data, targets = format_post_data(start_date, end_date)\n",
    "    print(\"Fitting model...\")\n",
    "    text_clf.fit(train_data, targets)\n",
    "    print(\"Saving model...\")\n",
    "    dump(text_clf, \"10k_so_se_bayes_model.joblib\")\n",
    "\n",
    "def test_model_bayes():\n",
    "    text_clf = load(\"10k_so_se_bayes_model.joblib\") \n",
    "    # the date range to test with\n",
    "    test_start_date = datetime.date(2019, 1, 1)\n",
    "    test_end_date = datetime.date(2019, 1, 31)\n",
    "    test_data, test_targets = format_post_data(test_start_date, test_end_date)\n",
    "    predictions = text_clf.predict(test_data)\n",
    "    accuracy = np.mean(predictions == test_targets)\n",
    "    print(\"accuracy of model: \" + str(accuracy))\n",
    "    print(metrics.classification_report(test_targets, predictions, target_names=[\"stackoverflow.com\", \"softwareengineering.stackexchange.com\"]))\n",
    "    print(metrics.confusion_matrix(test_targets, predictions))\n",
    "\n",
    "def bayes():\n",
    "    train_bayes()\n",
    "    test_model_bayes()\n",
    "\n",
    "def train_SVM():\n",
    "    text_clf = Pipeline([ ('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 4, 30)\n",
    "    train_data, targets = format_post_data(start_date, end_date)\n",
    "    print(\"Fitting model...\")\n",
    "    text_clf.fit(train_data, targets)\n",
    "    print(\"Saving model...\")\n",
    "    dump(text_clf, \"10k_so_se_SVM_model.joblib\")\n",
    "\n",
    "def test_model_SVM():\n",
    "    text_clf = load(\"10k_so_se_SVM_model.joblib\") \n",
    "    # the date range to test with\n",
    "    test_start_date = datetime.date(2019, 1, 1)\n",
    "    test_end_date = datetime.date(2019, 1, 31)\n",
    "    test_data, test_targets = format_post_data(test_start_date, test_end_date)\n",
    "    predictions = text_clf.predict(test_data)\n",
    "    print(metrics.classification_report(test_targets, predictions, target_names=[\"stackoverflow.com\", \"softwareengineering.stackexchange.com\"]))\n",
    "    print(metrics.confusion_matrix(test_targets, predictions))\n",
    "\n",
    "def SVM():\n",
    "    train_SVM()\n",
    "    test_model_SVM()\n",
    "\n",
    "bayes()\n",
    "SVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
